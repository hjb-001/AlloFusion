{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PASSer predictions for ensemble, automl, and rank models created successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import shutil\n",
    "\n",
    "# PASSer API URL\n",
    "api_url = 'https://passer.smu.edu/api'\n",
    "\n",
    "# Directories\n",
    "alloFusion_prediction_set_dir = 'AlloFusion_prediction_set'\n",
    "passer_ensemble_dir = 'passer_ensemble_prediction_set'\n",
    "passer_automl_dir = 'passer_automl_prediction_set'\n",
    "passer_rank_dir = 'passer_rank_prediction_set'\n",
    "\n",
    "# Create the passer directories if they don't exist\n",
    "for dir_name in [passer_ensemble_dir, passer_rank_dir]:\n",
    "    if not os.path.exists(dir_name):\n",
    "        os.makedirs(dir_name)\n",
    "\n",
    "# Function to query PASSer API and get AFR residues for different models\n",
    "def get_passer_prediction(pdb_code, chain_name, model):\n",
    "    data = {\"pdb\": pdb_code, \"chain\": chain_name, \"model\": model}\n",
    "    response = requests.post(api_url, data=data)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f\"Error: Could not retrieve results for {pdb_code} chain {chain_name} using model {model}\")\n",
    "        return None\n",
    "\n",
    "# Function to generate .txt content for AFR (Prediction 1 only)\n",
    "def generate_txt_content(prediction_data):\n",
    "    txt_content = \"PASSer Allosteric Site Forming Residues (Top Prediction):\\n\\n\"\n",
    "    # Process only the first prediction (\"1\")\n",
    "    if \"1\" in prediction_data:\n",
    "        value = prediction_data[\"1\"]\n",
    "        txt_content += f\"Top Prediction: {value['prob']} probability\\n\"\n",
    "        txt_content += f\"Residues: {value['residues']}\\n\\n\"\n",
    "    else:\n",
    "        txt_content += \"No top prediction available.\\n\"\n",
    "    return txt_content\n",
    "\n",
    "# Function to generate .pml content for AFR (Prediction 1 only)\n",
    "def generate_pml_content(pdb_code, chain_name, prediction_data):\n",
    "    pml_content = f\"# PyMOL script to highlight allosteric sites in {pdb_code}\\n\"\n",
    "    pml_content += f\"fetch {pdb_code}\\n\"\n",
    "    pml_content += \"hide everything\\n\"\n",
    "    pml_content += f\"show cartoon, chain {chain_name}\\n\"\n",
    "    pml_content += f\"color spectrum, chain {chain_name}\\n\"\n",
    "    \n",
    "    # Process only the first prediction (\"1\")\n",
    "    if \"1\" in prediction_data:\n",
    "        value = prediction_data[\"1\"]\n",
    "        residues = value['residues'].split('resid ')[-1]\n",
    "        for res_num in residues.split():\n",
    "            pml_content += f\"select resi {res_num} and chain {chain_name}\\n\"\n",
    "            pml_content += f\"show surface, resi {res_num} and chain {chain_name}\\n\"\n",
    "            pml_content += f\"color green, resi {res_num} and chain {chain_name}\\n\"\n",
    "            pml_content += f\"set transparency, 0.2, resi {res_num} and chain {chain_name}\\n\"\n",
    "    \n",
    "    pml_content += f\"zoom chain {chain_name}\\n\"\n",
    "    return pml_content\n",
    "\n",
    "# Automatically build pdb_chain_list from the subfolder names in AlloFusion_prediction_set\n",
    "pdb_chain_list = []\n",
    "for folder in os.listdir(alloFusion_prediction_set_dir): \n",
    "    pdb_code, chain_name= folder.split('_')\n",
    "    pdb_chain_list.append({\"pdb\": pdb_code, \"chain\": chain_name})\n",
    "\n",
    "# Loop over each PDB code and chain for all three models\n",
    "for pdb_chain in pdb_chain_list:\n",
    "    pdb_code = pdb_chain[\"pdb\"]\n",
    "    chain_name = pdb_chain[\"chain\"]\n",
    "    \n",
    "    # Query PASSer API for the ensemble, automl, and rank models\n",
    "    for model, dir_name in zip(['ensemble', 'automl', 'rank'], \n",
    "                               [passer_ensemble_dir, passer_automl_dir,passer_rank_dir]):\n",
    "        prediction_data = get_passer_prediction(pdb_code, chain_name, model)\n",
    "        \n",
    "        if prediction_data:\n",
    "            # Create a folder for the protein and chain in the corresponding passer_set directory\n",
    "            protein_folder = f\"{pdb_code}_{chain_name}_passer_{model}\"\n",
    "            target_protein_dir = os.path.join(dir_name, protein_folder)\n",
    "            \n",
    "            if not os.path.exists(target_protein_dir):\n",
    "                os.makedirs(target_protein_dir)\n",
    "            \n",
    "            # Copy the two PDB files (protein and chain-specific PDB) from stingallo_prediction_set\n",
    "            protein_pdb_file = os.path.join(alloFusion_prediction_set_dir, f\"{pdb_code}_{chain_name}\", f\"{pdb_code}_protein.pdb\")\n",
    "            chain_pdb_file = os.path.join(alloFusion_prediction_set_dir, f\"{pdb_code}_{chain_name}\", f\"{pdb_code}_chain_{chain_name}.pdb\")\n",
    "            \n",
    "            # Check if both files exist before copying\n",
    "            if os.path.exists(protein_pdb_file):\n",
    "                shutil.copy(protein_pdb_file, target_protein_dir)\n",
    "            else:\n",
    "                print(f\"Warning: {protein_pdb_file} does not exist!\")\n",
    "            \n",
    "            # if os.path.exists(chain_pdb_file):\n",
    "            #     shutil.copy(chain_pdb_file, target_protein_dir)\n",
    "            # else:\n",
    "            #     print(f\"Warning: {chain_pdb_file} does not exist!\")\n",
    "            \n",
    "            # Generate and save the .txt file\n",
    "            txt_content = generate_txt_content(prediction_data)\n",
    "            txt_file_path = os.path.join(target_protein_dir, f\"{pdb_code}_passer_{model}_allosteric_residues.txt\")\n",
    "            with open(txt_file_path, 'w') as f:\n",
    "                f.write(txt_content)\n",
    "            \n",
    "            # Generate and save the .pml file\n",
    "            pml_content = generate_pml_content(pdb_code, chain_name, prediction_data)\n",
    "            pml_file_path = os.path.join(target_protein_dir, f\"{pdb_code}_passer_{model}_allosteric_sites.pml\")\n",
    "            with open(pml_file_path, 'w') as f:\n",
    "                f.write(pml_content)\n",
    "\n",
    "print(\"PASSer predictions for ensemble, automl, and rank models created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['51', '97', '98', '129', '244', '246', '250', '252', '275', '279', '287', '290', '291', '294', '300', '302', '305', '307', '317', '319', '321', '335', '337', '339']\n"
     ]
    }
   ],
   "source": [
    "# The following code is for generating .pml files for the AlloFusion prediction set\n",
    "import os\n",
    "import re\n",
    "stingallo_pred_dir = 'alloFusion_prediction_set'\n",
    "# Function to generate .pml content for AFR (Prediction 1 only)\n",
    "def generate_pml_content(pdb_code, chain_name, prediction_data):\n",
    "    pml_content = f\"# PyMOL script to highlight allosteric sites in {pdb_code}\\n\"\n",
    "    pml_content += f\"fetch {pdb_code}\\n\"\n",
    "    pml_content += \"hide everything\\n\"\n",
    "    pml_content += f\"show cartoon, chain {chain_name}\\n\"\n",
    "    pml_content += f\"color spectrum, chain {chain_name}\\n\"\n",
    "    \n",
    "    # Process only the first prediction (\"1\")\n",
    "    for res_num in prediction_data:\n",
    "        pml_content += f\"select resi {res_num} and chain {chain_name}\\n\"\n",
    "        pml_content += f\"show surface, resi {res_num} and chain {chain_name}\\n\"\n",
    "        pml_content += f\"color red, resi {res_num} and chain {chain_name}\\n\"\n",
    "        pml_content += f\"set transparency, 0.2, resi {res_num} and chain {chain_name}\\n\"\n",
    "    \n",
    "    pml_content += f\"zoom chain {chain_name}\\n\"\n",
    "    return pml_content\n",
    "\n",
    "# read file and extract the prediction data\n",
    "def get_prediction(pdb_code, chain_name):\n",
    "    dir_name = stingallo_pred_dir\n",
    "    txt_file_path = os.path.join(dir_name, f\"{pdb_code}_{chain_name}\", f\"{pdb_code}_allosteric_residues.txt\")\n",
    "    residues = []\n",
    "    if os.path.exists(txt_file_path):\n",
    "        with open(txt_file_path, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            for line in lines:\n",
    "                residues = re.findall(r'-?\\d+', line)\n",
    "    return residues\n",
    "\n",
    "# Automatically build pdb_chain_list from the subfolder names in AlloFusion_prediction_set\n",
    "pdb_chain_list = [{'pdb':'6E3U','chain':'B'}]\n",
    "# for folder in os.listdir(stingallo_pred_dir): \n",
    "#     pdb_code, chain_name= folder.split('_')\n",
    "#     pdb_chain_list.append({\"pdb\": pdb_code, \"chain\": chain_name})\n",
    "\n",
    "# Loop over each PDB code and chain for all three models\n",
    "for pdb_chain in pdb_chain_list:\n",
    "    pdb_code = pdb_chain[\"pdb\"]\n",
    "    chain_name = pdb_chain[\"chain\"]\n",
    "    prediction_data = get_prediction(pdb_code, chain_name)\n",
    "    print(prediction_data)\n",
    "    pml_content = generate_pml_content(pdb_code, chain_name, prediction_data)\n",
    "    target_protein_dir = os.path.join(stingallo_pred_dir, f\"{pdb_code}_{chain_name}\")\n",
    "    pml_file_path = os.path.join(target_protein_dir, f\"{pdb_code}_allosteric_sites.pml\")\n",
    "    with open(pml_file_path, 'w') as f:\n",
    "        f.write(pml_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from Bio.PDB import PDBParser\n",
    "import warnings\n",
    "import re\n",
    "\n",
    "# Directories for the actual and prediction sets\n",
    "actual_afr_dir = 'actual_afr_set'\n",
    "alloFusion_pred_dir = 'alloFusion_prediction_set'\n",
    "passer_ensemble_dir = 'passer_ensemble_prediction_set'\n",
    "passer_automl_dir = 'passer_automl_prediction_set'\n",
    "passer_rank_dir = 'passer_rank_prediction_set'\n",
    "passer_allositePro_dir = 'allositePro_prediction_set'\n",
    "deepAllo_pred_dir = 'DeepAllo_prediction_set'\n",
    "\n",
    "dcc_result_file = 'dccPlus_results.csv'\n",
    "success_rate_file = 'successPlus_rate.txt'\n",
    "\n",
    "# Initialize PDB parser\n",
    "parser = PDBParser(QUIET=True)  # Suppress warnings inside the parser\n",
    "\n",
    "# Function to get the centroid of a list of residues\n",
    "def calculate_centroid(residues,actual_centroid=None):\n",
    "    coords = [atom.get_coord() for residue in residues for atom in residue.get_atoms() if atom.get_name() == 'CA']\n",
    "    coords1=[]\n",
    "    if coords:\n",
    "        if actual_centroid is not None:\n",
    "            for coord in coords:\n",
    "                if np.linalg.norm(coord-actual_centroid)<=100:\n",
    "                    coords1.append(coord)\n",
    "            if coords1:  # Ensure coords1 is not empty\n",
    "                centroid = np.mean(coords1, axis=0)\n",
    "                return centroid\n",
    "            else:\n",
    "                return None  # Return None if coords1 is empty\n",
    "        else:\n",
    "            centroid = np.mean(coords, axis=0)\n",
    "            return centroid\n",
    "    return None\n",
    "\n",
    "# Function to extract residues from a PDB file based on residue numbers\n",
    "def extract_residues(pdb_file, chain_id, residue_numbers):\n",
    "    try:\n",
    "        structure = parser.get_structure('protein', pdb_file)\n",
    "        chain = structure[0][chain_id]\n",
    "        residues = [chain[res_id] for res_id in residue_numbers if res_id in chain]\n",
    "        return residues\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting residues from {pdb_file}, Chain {chain_id}: {e}\")\n",
    "        return []\n",
    "\n",
    "# Function to calculate DCC for predicted vs actual\n",
    "def calculate_dcc(actual_residues, predicted_residues):\n",
    "    if not actual_residues or not predicted_residues:\n",
    "        return None  # Handle cases where no AFR exists or missing residues\n",
    "    actual_centroid = calculate_centroid(actual_residues)\n",
    "    predicted_centroid = calculate_centroid(predicted_residues,actual_centroid)\n",
    "    if actual_centroid is None or predicted_centroid is None:\n",
    "        return None  # No valid centroids to calculate distance\n",
    "    \n",
    "    distance = np.linalg.norm(actual_centroid - predicted_centroid)\n",
    "    return distance\n",
    "\n",
    "# Helper function to extract residue numbers from the .pml file\n",
    "def get_residue_numbers_from_pml(pml_file_path):\n",
    "    residue_numbers = []\n",
    "    if os.path.exists(pml_file_path):\n",
    "        with open(pml_file_path, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            for line in lines:\n",
    "                # Look for lines with 'resi' followed by a number\n",
    "                match = re.findall(r'\\bresi (\\d+)', line)\n",
    "                if match:\n",
    "                    residue_numbers.extend([int(res_num) for res_num in match])\n",
    "    return list(set(residue_numbers))\n",
    "\n",
    "# Function to calculate metrics (EPR, SR) based on true and predicted residues\n",
    "def calculate_metrics(true_residues, predicted_residues):\n",
    "    tp = len(set(true_residues) & set(predicted_residues))\n",
    "    fp = len(set(predicted_residues) - set(true_residues))  # False Positive\n",
    "    fn = len(set(true_residues) - set(predicted_residues))  # False Negative\n",
    "   \n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    sr=tp/len(true_residues)\n",
    "    sr=round(sr,2)\n",
    "    epr=0\n",
    "    # （EPR）\n",
    "    if tp>=1:\n",
    "        epr=1\n",
    "    else:\n",
    "        epr=0\n",
    "    return epr\n",
    "\n",
    "# Function to process a single set and calculate DCC\n",
    "def process_set(actual_afr_dir, pred_dir, set_name):\n",
    "    dcc_data = []\n",
    "    success_count = 0\n",
    "    total_count = 0\n",
    "    \n",
    "    for folder in os.listdir(actual_afr_dir):\n",
    "        if folder.endswith('_target'):  # Match actual target folders\n",
    "            pdb_code, chain = folder.split('_')[:2]\n",
    "            actual_pdb_file = os.path.join(actual_afr_dir, folder, f'{pdb_code}.pdb')\n",
    "            # print(actual_pdb_file)\n",
    "            if set_name == \"alloFusion\":\n",
    "                pred_pdb_file = os.path.join(alloFusion_pred_dir, f'{pdb_code}_{chain}', f'{pdb_code}_protein.pdb')\n",
    "                pml_file_path = os.path.join(alloFusion_pred_dir, f'{pdb_code}_{chain}', f'{pdb_code}_allosteric_sites.pml')\n",
    "            elif set_name == \"passer_ensemble\":\n",
    "                pred_pdb_file = os.path.join(passer_ensemble_dir, f'{pdb_code}_{chain}_passer_ensemble', f'{pdb_code}_protein.pdb')\n",
    "                pml_file_path = os.path.join(passer_ensemble_dir, f'{pdb_code}_{chain}_passer_ensemble', f'{pdb_code}_passer_ensemble_allosteric_sites.pml')\n",
    "            elif set_name == \"AllositePro\":\n",
    "                pred_pdb_file = os.path.join(passer_allositePro_dir, f'{pdb_code}_{chain}', f'{pdb_code}.pdb')\n",
    "                pml_file_path = os.path.join(passer_allositePro_dir, f'{pdb_code}_{chain}', f'{pdb_code}_allosteric_sites.pml')\n",
    "            elif set_name == \"passer_rank\":\n",
    "                pred_pdb_file = os.path.join(passer_rank_dir, f'{pdb_code}_{chain}_passer_rank', f'{pdb_code}_protein.pdb')\n",
    "                pml_file_path = os.path.join(passer_rank_dir, f'{pdb_code}_{chain}_passer_rank', f'{pdb_code}_passer_rank_allosteric_sites.pml')\n",
    "            elif set_name == \"passer_automl\":\n",
    "                pred_pdb_file = os.path.join(passer_automl_dir, f'{pdb_code}_{chain}_passer_automl', f'{pdb_code}_protein.pdb')\n",
    "                pml_file_path = os.path.join(passer_automl_dir, f'{pdb_code}_{chain}_passer_automl', f'{pdb_code}_passer_automl_allosteric_sites.pml')\n",
    "            elif set_name == \"deepAllo\":\n",
    "                pred_pdb_file = os.path.join(deepAllo_pred_dir, f'{pdb_code}_{chain}', f'{pdb_code}_protein.pdb')\n",
    "                pml_file_path = os.path.join(deepAllo_pred_dir, f'{pdb_code}_{chain}', f'{pdb_code}_allosteric_sites.pml')\n",
    "            else:\n",
    "                continue  # Unknown set\n",
    "\n",
    "            if not os.path.exists(pred_pdb_file) or not os.path.exists(pml_file_path):\n",
    "                print(f\"Prediction file or PML file not found for {pdb_code} Chain {chain} in {set_name}. Skipping...\")\n",
    "                continue  # Skip if the prediction file or PML file doesn't exist\n",
    "            \n",
    "            # Get the list of actual and predicted residue numbers (from the .pml files)\n",
    "            actual_residue_numbers = get_residue_numbers_from_pml(os.path.join(actual_afr_dir, folder, f'{pdb_code}_allosteric_sites.pml'))\n",
    "            pred_residue_numbers = get_residue_numbers_from_pml(pml_file_path)\n",
    "           \n",
    "            if not actual_residue_numbers or not pred_residue_numbers:\n",
    "                print(f\"No AFRs found for {pdb_code} Chain {chain} in {set_name}. Skipping...\")\n",
    "                continue  # Skip if no AFRs found in either actual or predicted\n",
    "            \n",
    "        \n",
    "             # Extract residues from PDB files\n",
    "            actual_residues = extract_residues(actual_pdb_file, chain, actual_residue_numbers)\n",
    "            predicted_residues = extract_residues(pred_pdb_file, chain, pred_residue_numbers)\n",
    "\n",
    "             # Calculate DCC\n",
    "            dcc = calculate_dcc(actual_residues, predicted_residues)\n",
    "            if dcc is not None:\n",
    "                dcc_data.append([pdb_code, chain, dcc, set_name])\n",
    "            \n",
    "            # Increment counters for success rate\n",
    "            epr=calculate_metrics(actual_residue_numbers, pred_residue_numbers)\n",
    "            # if epr is not None:\n",
    "            #     dcc_data.append([pdb_code, chain, epr, set_name])\n",
    "            if epr is not None and epr == 1:\n",
    "                success_count += 1\n",
    "            total_count += 1\n",
    "    \n",
    "    return dcc_data, success_count, total_count\n",
    "\n",
    "# Process the four sets: stingallo, passer_ensemble, passer_automl, passer_rank\n",
    "dcc_data = []\n",
    "\n",
    "# Process alloFusion set\n",
    "alloFusion_dcc_data, stingallo_success, stingallo_total = process_set(actual_afr_dir, alloFusion_pred_dir, 'alloFusion')\n",
    "\n",
    "# Process passer_ensemble set\n",
    "passer_ensemble_dcc_data, passer_ensemble_success, passer_ensemble_total = process_set(actual_afr_dir, passer_ensemble_dir, 'passer_ensemble')\n",
    "\n",
    "# Process allositePro set\n",
    "passer_allositePro_dcc_data, passer_allositePro_success, passer_allositePro_total = process_set(actual_afr_dir, passer_allositePro_dir, 'AllositePro')\n",
    "\n",
    "# Process passer_rank set\n",
    "passer_rank_dcc_data, passer_rank_success, passer_rank_total = process_set(actual_afr_dir, passer_rank_dir, 'passer_rank')\n",
    "\n",
    "# Process passer_automl set\n",
    "passer_automl_dcc_data, passer_automl_success, passer_automl_total = process_set(actual_afr_dir, passer_automl_dir, 'passer_automl')\n",
    "\n",
    "# Process deepAllo set\n",
    "deepAllo_dcc_data, deepAllo_success, deepAllo_total = process_set(actual_afr_dir, deepAllo_pred_dir, 'deepAllo')\n",
    "print(deepAllo_success,deepAllo_total)\n",
    "# Merge DCC results for all sets into a single output with 5 columns\n",
    "dcc_result = {}\n",
    "for pdb_code, chain, dcc_stingallo, _ in alloFusion_dcc_data:\n",
    "    dcc_result[(pdb_code, chain)] = {'DCC_alloFusion': dcc_stingallo}\n",
    "\n",
    "for pdb_code, chain, dcc_ensemble, _ in passer_ensemble_dcc_data:\n",
    "    if (pdb_code, chain) in dcc_result:\n",
    "        dcc_result[(pdb_code, chain)]['DCC_passer_ensemble'] = dcc_ensemble\n",
    "    else:\n",
    "        dcc_result[(pdb_code, chain)] = {'DCC_passer_ensemble': dcc_ensemble}\n",
    "\n",
    "for pdb_code, chain, dcc_allositePro, _ in passer_allositePro_dcc_data:\n",
    "    if (pdb_code, chain) in dcc_result:\n",
    "        dcc_result[(pdb_code, chain)]['DCC_AllositePro'] = dcc_allositePro\n",
    "    else:\n",
    "        dcc_result[(pdb_code, chain)] = {'DCC_AllositePro': dcc_allositePro}\n",
    "\n",
    "for pdb_code, chain, dcc_rank, _ in passer_rank_dcc_data:\n",
    "    if (pdb_code, chain) in dcc_result:\n",
    "        dcc_result[(pdb_code, chain)]['DCC_passer_rank'] = dcc_rank\n",
    "    else:\n",
    "        dcc_result[(pdb_code, chain)] = {'DCC_passer_rank': dcc_rank}\n",
    "\n",
    "for pdb_code, chain, dcc_automl, _ in passer_automl_dcc_data:\n",
    "    if (pdb_code, chain) in dcc_result:\n",
    "        dcc_result[(pdb_code, chain)]['DCC_passer_automl'] = dcc_automl\n",
    "    else:\n",
    "        dcc_result[(pdb_code, chain)] = {'DCC_passer_automl': dcc_automl}\n",
    "for pdb_code, chain, dcc_deepAllo, _ in deepAllo_dcc_data:\n",
    "    if (pdb_code, chain) in dcc_result:\n",
    "        dcc_result[(pdb_code, chain)]['DCC_deepAllo'] = dcc_deepAllo\n",
    "    else:\n",
    "        dcc_result[(pdb_code, chain)] = {'DCC_deepAllo': dcc_deepAllo}\n",
    "\n",
    "# Create a DataFrame with the results\n",
    "dcc_result_list = []\n",
    "for (pdb_code, chain), dcc_values in dcc_result.items():\n",
    "    dcc_alloFusion = dcc_values.get('DCC_alloFusion', 'N/A')\n",
    "    dcc_passer_allositePro = dcc_values.get('DCC_AllositePro', 'N/A')\n",
    "    dcc_passer_rank = dcc_values.get('DCC_passer_rank', 'N/A')\n",
    "    dcc_passer_ensemble = dcc_values.get('DCC_passer_ensemble', 'N/A')\n",
    "    dcc_passer_automl = dcc_values.get('DCC_passer_automl', 'N/A')\n",
    "    dcc_deepAllo = dcc_values.get('DCC_deepAllo', 'N/A')\n",
    "    dcc_result_list.append([pdb_code, chain, dcc_alloFusion,  dcc_passer_allositePro, dcc_passer_rank,dcc_passer_ensemble,dcc_passer_automl, dcc_deepAllo])\n",
    "\n",
    "dcc_df = pd.DataFrame(dcc_result_list, columns=['PDB_Code', 'Chain', 'DCC_alloFusion', 'DCC_AllositesitePro', 'DCC_passer_rank','DCC_passer_ensemble','DCC_passer_automl','DCC_deepAllo'])\n",
    "dcc_df.to_csv(dcc_result_file, index=False)\n",
    "\n",
    "# Calculate success rates\n",
    "alloFusion_success_rate = stingallo_success / stingallo_total if stingallo_total > 0 else 0\n",
    "passer_ensemble_success_rate = passer_ensemble_success / passer_ensemble_total if passer_ensemble_total > 0 else 0\n",
    "passer_allositePro_success_rate = passer_allositePro_success / passer_allositePro_total if passer_allositePro_total > 0 else 0\n",
    "passer_rank_success_rate = passer_rank_success / passer_rank_total if passer_rank_total > 0 else 0\n",
    "passer_automl_success_rate = passer_automl_success / passer_automl_total if passer_automl_total > 0 else 0\n",
    "deepAllo_success_rate = deepAllo_success / deepAllo_total if deepAllo_total > 0 else 0\n",
    "# Write success rates to file\n",
    "with open(success_rate_file, 'w') as f:\n",
    "    f.write(f\"alloFusion Success Rate: {alloFusion_success_rate:.2%}\\n\")\n",
    "    f.write(f\"Passer allositePro Success Rate: {passer_allositePro_success_rate:.2%}\\n\")\n",
    "    f.write(f\"Passer Rank Success Rate: {passer_rank_success_rate:.2%}\\n\")\n",
    "    f.write(f\"Passer Ensemble Success Rate: {passer_ensemble_success_rate:.2%}\\n\")\n",
    "    f.write(f\"Passer Automl Success Rate: {passer_automl_success_rate:.2%}\\n\")\n",
    "    f.write(f\"DeepAllo Success Rate: {deepAllo_success_rate:.2%}\\n\")\n",
    "print(\"DCC calculations and success rate evaluation complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
